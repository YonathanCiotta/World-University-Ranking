{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0522d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba29611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "840cc4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the full file path on the external hard disk\n",
    "pickle_filepath = os.path.join(external_hard_disk_path, folder_path, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad331c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Given paths and file name\n",
    "external_hard_disk_path = \"/Volumes/One Touch\"\n",
    "folder_path = \"World University Ranking/02 Data/Original Data\"\n",
    "file_name = \"cwurData.csv\"\n",
    "\n",
    "# Define the full file path on the external hard disk\n",
    "full_file_path = os.path.join(external_hard_disk_path, folder_path, file_name)\n",
    "\n",
    "print(full_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c87b52",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the data into a pandas DataFrame\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Display the first few rows to understand the structure of the data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial data preview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv'\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure of the data\n",
    "print(\"Initial data preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Example of data cleaning operations:\n",
    "# 1. Handling missing values (if any)\n",
    "# Replace missing values with NaN\n",
    "df.replace('na', pd.NA, inplace=True)\n",
    "df.replace('NA', pd.NA, inplace=True)\n",
    "df.replace('-', pd.NA, inplace=True)\n",
    "\n",
    "# 2. Dropping duplicates (if necessary)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 3. Data type conversions (if necessary)\n",
    "# For example, converting numeric columns from string to numeric\n",
    "numeric_columns = ['score', 'national_rank', 'quality_of_education']\n",
    "df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 4. Renaming columns (if necessary)\n",
    "# Example: Rename columns for better readability\n",
    "df.rename(columns={'institution': 'university_name', 'country': 'country_name'}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f433d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = '//Users/yonathanciotta/Downloads/cwurData.csv'\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File exists!\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "530fbb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data preview:\n",
      "   world_rank                            institution         country  \\\n",
      "0           1                     Harvard University             USA   \n",
      "1           2  Massachusetts Institute of Technology             USA   \n",
      "2           3                    Stanford University             USA   \n",
      "3           4                University of Cambridge  United Kingdom   \n",
      "4           5     California Institute of Technology             USA   \n",
      "\n",
      "   national_rank  quality_of_education  alumni_employment  quality_of_faculty  \\\n",
      "0              1                     7                  9                   1   \n",
      "1              2                     9                 17                   3   \n",
      "2              3                    17                 11                   5   \n",
      "3              1                    10                 24                   4   \n",
      "4              4                     2                 29                   7   \n",
      "\n",
      "   publications  influence  citations  broad_impact  patents   score  year  \n",
      "0             1          1          1           NaN        5  100.00  2012  \n",
      "1            12          4          4           NaN        1   91.67  2012  \n",
      "2             4          2          2           NaN       15   89.50  2012  \n",
      "3            16         16         11           NaN       50   86.17  2012  \n",
      "4            37         22         22           NaN       18   85.21  2012  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/Users/yonathanciotta/Downloads/cwurData.csv'\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure of the data\n",
    "print(\"Initial data preview:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e13658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " world_rank                0\n",
      "institution               0\n",
      "country                   0\n",
      "national_rank             0\n",
      "quality_of_education      0\n",
      "alumni_employment         0\n",
      "quality_of_faculty        0\n",
      "publications              0\n",
      "influence                 0\n",
      "citations                 0\n",
      "broad_impact            200\n",
      "patents                   0\n",
      "score                     0\n",
      "year                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61615b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'year' column to datetime format (if not already)\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a754026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows if any\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "811cc61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Rename columns to lowercase for consistency\n",
    "df.columns = df.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32a82e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Standardize country names (assuming 'country' column)\n",
    "df['country'] = df['country'].str.strip().str.lower().replace({\n",
    "    'united states of america': 'usa',\n",
    "    'united kingdom': 'uk',\n",
    "    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b54faaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to /Users/yonathanciotta/Downloads/cwurData_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned DataFrame to a new CSV file\n",
    "cleaned_file_path = '/Users/yonathanciotta/Downloads/cwurData_cleaned.csv'\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b51022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where broad_impact is NaN\n",
    "df.dropna(subset=['broad_impact'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d79e8480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r3/g4d_jbx96_zbkgnnptpzq5sr0000gn/T/ipykernel_3064/75163870.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['broad_impact'].fillna(mean_broad_impact, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Example: Impute missing values with the mean of the column\n",
    "mean_broad_impact = df['broad_impact'].mean()\n",
    "df['broad_impact'].fillna(mean_broad_impact, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4e26683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values after cleaning:\n",
      " world_rank              0\n",
      "institution             0\n",
      "country                 0\n",
      "national_rank           0\n",
      "quality_of_education    0\n",
      "alumni_employment       0\n",
      "quality_of_faculty      0\n",
      "publications            0\n",
      "influence               0\n",
      "citations               0\n",
      "broad_impact            0\n",
      "patents                 0\n",
      "score                   0\n",
      "year                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where broad_impact is NaN\n",
    "df_cleaned = df.dropna(subset=['broad_impact'])\n",
    "\n",
    "# Confirming the missing values after cleaning\n",
    "missing_values_cleaned = df_cleaned.isnull().sum()\n",
    "print(\"Missing Values after cleaning:\\n\", missing_values_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91e3fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of broad_impact\n",
    "mean_broad_impact = df['broad_impact'].mean()\n",
    "\n",
    "# Fill missing values with mean using a dictionary\n",
    "df['broad_impact'] = df['broad_impact'].fillna(mean_broad_impact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85d034da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of broad_impact\n",
    "mean_broad_impact = df['broad_impact'].mean()\n",
    "\n",
    "# Directly assign the filled values\n",
    "df['broad_impact'] = df['broad_impact'].fillna(mean_broad_impact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05cdf5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values after cleaning:\n",
      " world_rank              0\n",
      "institution             0\n",
      "country                 0\n",
      "national_rank           0\n",
      "quality_of_education    0\n",
      "alumni_employment       0\n",
      "quality_of_faculty      0\n",
      "publications            0\n",
      "influence               0\n",
      "citations               0\n",
      "broad_impact            0\n",
      "patents                 0\n",
      "score                   0\n",
      "year                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Calculate mean of broad_impact\n",
    "mean_broad_impact = df['broad_impact'].mean()\n",
    "\n",
    "# Fill missing values in broad_impact column\n",
    "df['broad_impact'] = df['broad_impact'].fillna(mean_broad_impact)\n",
    "\n",
    "# Confirming the missing values after cleaning\n",
    "missing_values_cleaned = df.isnull().sum()\n",
    "print(\"Missing Values after cleaning:\\n\", missing_values_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b37bdd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics:\n",
      "        world_rank  national_rank  quality_of_education  alumni_employment  \\\n",
      "count  2000.000000    2000.000000           2000.000000        2000.000000   \n",
      "mean    500.500000      42.518000            296.001500         385.263500   \n",
      "min       1.000000       1.000000              1.000000           1.000000   \n",
      "25%     250.750000       7.000000            250.750000         250.750000   \n",
      "50%     500.500000      22.000000            355.000000         478.000000   \n",
      "75%     750.250000      52.000000            367.000000         500.250000   \n",
      "max    1000.000000     229.000000            367.000000         567.000000   \n",
      "std     288.747186      53.444193            106.868798         171.874782   \n",
      "\n",
      "       quality_of_faculty  publications   influence    citations  \\\n",
      "count         2000.000000   2000.000000  2000.00000  2000.000000   \n",
      "mean           191.127500    500.415000   500.21900   449.341500   \n",
      "min              1.000000      1.000000     1.00000     1.000000   \n",
      "25%            210.000000    250.750000   250.75000   234.000000   \n",
      "50%            210.000000    500.500000   500.50000   428.000000   \n",
      "75%            218.000000    750.000000   750.25000   645.000000   \n",
      "max            218.000000   1000.000000   991.00000   812.000000   \n",
      "std             52.402579    288.674823   288.30505   250.141228   \n",
      "\n",
      "       broad_impact      patents        score                 year  \n",
      "count   2000.000000  2000.000000  2000.000000                 2000  \n",
      "mean     496.699500   470.321000    47.067630  2014-07-02 12:00:00  \n",
      "min        1.000000     1.000000    44.020000  2014-01-01 00:00:00  \n",
      "25%      250.500000   242.750000    44.440000  2014-01-01 00:00:00  \n",
      "50%      496.000000   481.000000    44.960000  2014-07-02 12:00:00  \n",
      "75%      741.000000   737.000000    46.812500  2015-01-01 00:00:00  \n",
      "max     1000.000000   871.000000   100.000000  2015-01-01 00:00:00  \n",
      "std      286.919755   259.625408     6.590461                  NaN  \n"
     ]
    }
   ],
   "source": [
    "# Basic descriptive statistics\n",
    "descriptive_stats = df.describe()\n",
    "\n",
    "# Displaying descriptive statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(descriptive_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8ed2125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types and non-null counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2000 entries, 200 to 2199\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   world_rank            2000 non-null   int64         \n",
      " 1   institution           2000 non-null   object        \n",
      " 2   country               2000 non-null   object        \n",
      " 3   national_rank         2000 non-null   int64         \n",
      " 4   quality_of_education  2000 non-null   int64         \n",
      " 5   alumni_employment     2000 non-null   int64         \n",
      " 6   quality_of_faculty    2000 non-null   int64         \n",
      " 7   publications          2000 non-null   int64         \n",
      " 8   influence             2000 non-null   int64         \n",
      " 9   citations             2000 non-null   int64         \n",
      " 10  broad_impact          2000 non-null   float64       \n",
      " 11  patents               2000 non-null   int64         \n",
      " 12  score                 2000 non-null   float64       \n",
      " 13  year                  2000 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(9), object(2)\n",
      "memory usage: 234.4+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "world_rank              0\n",
      "institution             0\n",
      "country                 0\n",
      "national_rank           0\n",
      "quality_of_education    0\n",
      "alumni_employment       0\n",
      "quality_of_faculty      0\n",
      "publications            0\n",
      "influence               0\n",
      "citations               0\n",
      "broad_impact            0\n",
      "patents                 0\n",
      "score                   0\n",
      "year                    0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in 'country' column:\n",
      "['usa' 'uk' 'japan' 'switzerland' 'israel' 'south korea' 'canada' 'france'\n",
      " 'russia' 'china' 'taiwan' 'sweden' 'singapore' 'denmark' 'germany'\n",
      " 'netherlands' 'italy' 'belgium' 'australia' 'finland' 'norway'\n",
      " 'south africa' 'spain' 'brazil' 'hong kong' 'ireland' 'austria'\n",
      " 'new zealand' 'portugal' 'thailand' 'czech republic' 'malaysia' 'india'\n",
      " 'greece' 'mexico' 'hungary' 'argentina' 'turkey' 'poland' 'saudi arabia'\n",
      " 'chile' 'iceland' 'slovenia' 'estonia' 'lebanon' 'croatia' 'colombia'\n",
      " 'slovak republic' 'iran' 'egypt' 'serbia' 'bulgaria' 'lithuania' 'uganda'\n",
      " 'united arab emirates' 'uruguay' 'cyprus' 'romania' 'puerto rico']\n",
      "\n",
      "Value counts in 'country' column:\n",
      "country\n",
      "usa                     458\n",
      "china                   167\n",
      "japan                   148\n",
      "uk                      129\n",
      "germany                 110\n",
      "france                   99\n",
      "italy                    94\n",
      "spain                    81\n",
      "south korea              70\n",
      "canada                   65\n",
      "australia                54\n",
      "taiwan                   46\n",
      "brazil                   36\n",
      "india                    31\n",
      "netherlands              26\n",
      "austria                  24\n",
      "sweden                   22\n",
      "turkey                   20\n",
      "belgium                  20\n",
      "finland                  18\n",
      "poland                   18\n",
      "switzerland              18\n",
      "iran                     16\n",
      "ireland                  16\n",
      "greece                   14\n",
      "portugal                 14\n",
      "israel                   14\n",
      "hungary                  12\n",
      "hong kong                12\n",
      "new zealand              12\n",
      "norway                   10\n",
      "czech republic           10\n",
      "south africa             10\n",
      "denmark                  10\n",
      "egypt                     8\n",
      "chile                     8\n",
      "saudi arabia              8\n",
      "russia                    8\n",
      "argentina                 7\n",
      "thailand                  6\n",
      "malaysia                  6\n",
      "mexico                    4\n",
      "colombia                  4\n",
      "singapore                 4\n",
      "slovenia                  4\n",
      "romania                   3\n",
      "lebanon                   2\n",
      "croatia                   2\n",
      "estonia                   2\n",
      "slovak republic           2\n",
      "iceland                   2\n",
      "serbia                    2\n",
      "bulgaria                  2\n",
      "lithuania                 2\n",
      "uganda                    2\n",
      "united arab emirates      2\n",
      "uruguay                   2\n",
      "cyprus                    2\n",
      "puerto rico               2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking data types and non-null counts\n",
    "print(\"\\nData types and non-null counts:\")\n",
    "print(df.info())\n",
    "\n",
    "# Checking for missing values again after cleaning\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Checking unique values in categorical columns\n",
    "print(\"\\nUnique values in 'country' column:\")\n",
    "print(df['country'].unique())\n",
    "\n",
    "# Checking value counts in categorical columns\n",
    "print(\"\\nValue counts in 'country' column:\")\n",
    "print(df['country'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abbbabe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook saved as pickle to: /Users/yonathanciotta/Downloads/World_University_Ranking.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Specify the notebook file name and path\n",
    "notebook_filename = 'World University Ranking.ipynb'\n",
    "current_notebook_path = os.path.abspath(os.path.join('/Users/yonathanciotta/Downloads', notebook_filename))\n",
    "\n",
    "# Specify the destination directory for the pickle file\n",
    "destination_directory = '/Users/yonathanciotta/Downloads/'\n",
    "\n",
    "# Specify the pickle file name and path\n",
    "pickle_filename = 'World_University_Ranking.pkl'\n",
    "destination_pickle_path = os.path.join(destination_directory, pickle_filename)\n",
    "\n",
    "# Serialize and save the notebook as a pickle file\n",
    "with open(current_notebook_path, 'rb') as notebook_file:\n",
    "    notebook_content = notebook_file.read()\n",
    "    with open(destination_pickle_path, 'wb') as pickle_file:\n",
    "        pickle.dump(notebook_content, pickle_file)\n",
    "\n",
    "print(f\"Notebook saved as pickle to: {destination_pickle_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a588ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"id\": \"eea0ada2\",\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"#import Libraries\\n\",\n",
      "    \"import pandas as pd\\n\",\n",
      "    \"import numpy as np\\n\",\n",
      "    \"import os\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 3,\n",
      "   \"id\": \"79ab93f3\",\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 6,\n",
      "   \"id\": \"05dfaf5e\",\n",
      "   \"metadata\": {},\n",
      "   \"outputs\"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Path to the pickle file\n",
    "pickle_filepath = '/Users/yonathanciotta/Downloads/World_University_Ranking.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pickle_filepath, 'rb') as file:\n",
    "    notebook_content = pickle.load(file)\n",
    "\n",
    "# Assuming the content is binary, convert to text for display\n",
    "notebook_text = notebook_content.decode('utf-8')\n",
    "\n",
    "# Print a portion of the notebook content to verify\n",
    "print(notebook_text[:500])  # Print the first 500 characters for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c604bfc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '{' on line 29 (3078563050.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[34], line 35\u001b[0;36m\u001b[0m\n\u001b[0;31m    ]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '{' on line 29\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the content of the notebook\n",
    "notebook_content = {\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"id\": \"eea0ada2\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#import Libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import os\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"id\": \"79ab93f3\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 6,\n",
    "   \"id\": \"05dfaf5e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": []\n",
    "   ]\n",
    "  }\n",
    " ]\n",
    "}\n",
    "\n",
    "# Define the path to save the pickle file\n",
    "pickle_path = '/Users/yonathanciotta/Downloads/World_University_Ranking.pkl'\n",
    "\n",
    "# Save the notebook content as a pickle file\n",
    "with open(pickle_path, 'wb') as file:\n",
    "    pickle.dump(notebook_content, file)\n",
    "\n",
    "print(f\"Notebook saved as pickle to: {pickle_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfc49f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 2,\\n   \"id\": \"eea0ada2\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"#import Libraries\\\\n\",\\n    \"import pandas as pd\\\\n\",\\n    \"import numpy as np\\\\n\",\\n    \"import os\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 3,\\n   \"id\": \"79ab93f3\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 6,\\n   \"id\": \"05dfaf5e\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"\\\\n\",\\n    \"\\\\n\",\\n    \"# Define the full file path on the external hard disk\\\\n\",\\n    \"pickle_filepath = os.path.join(external_hard_disk_path, folder_path, file_name)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 7,\\n   \"id\": \"b57970e9\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"import os\\\\n\",\\n    \"\\\\n\",\\n    \"# Given paths and file name\\\\n\",\\n    \"external_hard_disk_path = \\\\\"/Volumes/One Touch\\\\\"\\\\n\",\\n    \"folder_path = \\\\\"World University Ranking/02 Data/Original Data\\\\\"\\\\n\",\\n    \"file_name = \\\\\"cwurData.csv\\\\\"\\\\n\",\\n    \"\\\\n\",\\n    \"# Define the full file path on the external hard disk\\\\n\",\\n    \"full_file_path = os.path.join(external_hard_disk_path, folder_path, file_name)\\\\n\",\\n    \"\\\\n\",\\n    \"print(full_file_path)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 8,\\n   \"id\": \"dff0ffc3\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"ename\": \"FileNotFoundError\",\\n     \"evalue\": \"[Errno 2] No such file or directory: \\'/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv\\'\",\\n     \"output_type\": \"error\",\\n     \"traceback\": [\\n      \"\\\\u001b[0;31m---------------------------------------------------------------------------\\\\u001b[0m\",\\n      \"\\\\u001b[0;31mFileNotFoundError\\\\u001b[0m                         Traceback (most recent call last)\",\\n      \"Cell \\\\u001b[0;32mIn[8], line 7\\\\u001b[0m\\\\n\\\\u001b[1;32m      4\\\\u001b[0m file_path \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\u001b[38;5;124m/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv\\\\u001b[39m\\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\n\\\\u001b[1;32m      6\\\\u001b[0m \\\\u001b[38;5;66;03m# Load the data into a pandas DataFrame\\\\u001b[39;00m\\\\n\\\\u001b[0;32m----> 7\\\\u001b[0m df \\\\u001b[38;5;241m=\\\\u001b[39m pd\\\\u001b[38;5;241m.\\\\u001b[39mread_csv(file_path)\\\\n\\\\u001b[1;32m      9\\\\u001b[0m \\\\u001b[38;5;66;03m# Display the first few rows to understand the structure of the data\\\\u001b[39;00m\\\\n\\\\u001b[1;32m     10\\\\u001b[0m \\\\u001b[38;5;28mprint\\\\u001b[39m(\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mInitial data preview:\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m)\\\\n\",\\n      \"File \\\\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\\\\u001b[0m, in \\\\u001b[0;36mread_csv\\\\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\\\\u001b[0m\\\\n\\\\u001b[1;32m   1013\\\\u001b[0m kwds_defaults \\\\u001b[38;5;241m=\\\\u001b[39m _refine_defaults_read(\\\\n\\\\u001b[1;32m   1014\\\\u001b[0m     dialect,\\\\n\\\\u001b[1;32m   1015\\\\u001b[0m     delimiter,\\\\n\\\\u001b[0;32m   (...)\\\\u001b[0m\\\\n\\\\u001b[1;32m   1022\\\\u001b[0m     dtype_backend\\\\u001b[38;5;241m=\\\\u001b[39mdtype_backend,\\\\n\\\\u001b[1;32m   1023\\\\u001b[0m )\\\\n\\\\u001b[1;32m   1024\\\\u001b[0m kwds\\\\u001b[38;5;241m.\\\\u001b[39mupdate(kwds_defaults)\\\\n\\\\u001b[0;32m-> 1026\\\\u001b[0m \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m _read(filepath_or_buffer, kwds)\\\\n\",\\n      \"File \\\\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\\\\u001b[0m, in \\\\u001b[0;36m_read\\\\u001b[0;34m(filepath_or_buffer, kwds)\\\\u001b[0m\\\\n\\\\u001b[1;32m    617\\\\u001b[0m _validate_names(kwds\\\\u001b[38;5;241m.\\\\u001b[39mget(\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mnames\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m, \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m))\\\\n\\\\u001b[1;32m    619\\\\u001b[0m \\\\u001b[38;5;66;03m# Create the parser.\\\\u001b[39;00m\\\\n\\\\u001b[0;32m--> 620\\\\u001b[0m parser \\\\u001b[38;5;241m=\\\\u001b[39m TextFileReader(filepath_or_buffer, \\\\u001b[38;5;241m*\\\\u001b[39m\\\\u001b[38;5;241m*\\\\u001b[39mkwds)\\\\n\\\\u001b[1;32m    622\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m chunksize \\\\u001b[38;5;129;01mor\\\\u001b[39;00m iterator:\\\\n\\\\u001b[1;32m    623\\\\u001b[0m     \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m parser\\\\n\",\\n      \"File \\\\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\\\\u001b[0m, in \\\\u001b[0;36mTextFileReader.__init__\\\\u001b[0;34m(self, f, engine, **kwds)\\\\u001b[0m\\\\n\\\\u001b[1;32m   1617\\\\u001b[0m     \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39moptions[\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mhas_index_names\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m] \\\\u001b[38;5;241m=\\\\u001b[39m kwds[\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mhas_index_names\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m]\\\\n\\\\u001b[1;32m   1619\\\\u001b[0m \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39mhandles: IOHandles \\\\u001b[38;5;241m|\\\\u001b[39m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m\\\\n\\\\u001b[0;32m-> 1620\\\\u001b[0m \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39m_engine \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39m_make_engine(f, \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39mengine)\\\\n\",\\n      \"File \\\\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\\\\u001b[0m, in \\\\u001b[0;36mTextFileReader._make_engine\\\\u001b[0;34m(self, f, engine)\\\\u001b[0m\\\\n\\\\u001b[1;32m   1878\\\\u001b[0m     \\\\u001b[38;5;28;01mif\\\\u001b[39;00m \\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mb\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m \\\\u001b[38;5;129;01mnot\\\\u001b[39;00m \\\\u001b[38;5;129;01min\\\\u001b[39;00m mode:\\\\n\\\\u001b[1;32m   1879\\\\u001b[0m         mode \\\\u001b[38;5;241m+\\\\u001b[39m\\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mb\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\n\\\\u001b[0;32m-> 1880\\\\u001b[0m \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39mhandles \\\\u001b[38;5;241m=\\\\u001b[39m get_handle(\\\\n\\\\u001b[1;32m   1881\\\\u001b[0m     f,\\\\n\\\\u001b[1;32m   1882\\\\u001b[0m     mode,\\\\n\\\\u001b[1;32m   1883\\\\u001b[0m     encoding\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39moptions\\\\u001b[38;5;241m.\\\\u001b[39mget(\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mencoding\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m, \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m),\\\\n\\\\u001b[1;32m   1884\\\\u001b[0m     compression\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39moptions\\\\u001b[38;5;241m.\\\\u001b[39mget(\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mcompression\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m, \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m),\\\\n\\\\u001b[1;32m   1885\\\\u001b[0m     memory_map\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39moptions\\\\u001b[38;5;241m.\\\\u001b[39mget(\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mmemory_map\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m, \\\\u001b[38;5;28;01mFalse\\\\u001b[39;00m),\\\\n\\\\u001b[1;32m   1886\\\\u001b[0m     is_text\\\\u001b[38;5;241m=\\\\u001b[39mis_text,\\\\n\\\\u001b[1;32m   1887\\\\u001b[0m     errors\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39moptions\\\\u001b[38;5;241m.\\\\u001b[39mget(\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mencoding_errors\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m, \\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mstrict\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m),\\\\n\\\\u001b[1;32m   1888\\\\u001b[0m     storage_options\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39moptions\\\\u001b[38;5;241m.\\\\u001b[39mget(\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mstorage_options\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m, \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m),\\\\n\\\\u001b[1;32m   1889\\\\u001b[0m )\\\\n\\\\u001b[1;32m   1890\\\\u001b[0m \\\\u001b[38;5;28;01massert\\\\u001b[39;00m \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39mhandles \\\\u001b[38;5;129;01mis\\\\u001b[39;00m \\\\u001b[38;5;129;01mnot\\\\u001b[39;00m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m\\\\n\\\\u001b[1;32m   1891\\\\u001b[0m f \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39mhandles\\\\u001b[38;5;241m.\\\\u001b[39mhandle\\\\n\",\\n      \"File \\\\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\\\\u001b[0m, in \\\\u001b[0;36mget_handle\\\\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\\\\u001b[0m\\\\n\\\\u001b[1;32m    868\\\\u001b[0m \\\\u001b[38;5;28;01melif\\\\u001b[39;00m \\\\u001b[38;5;28misinstance\\\\u001b[39m(handle, \\\\u001b[38;5;28mstr\\\\u001b[39m):\\\\n\\\\u001b[1;32m    869\\\\u001b[0m     \\\\u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\\\\u001b[39;00m\\\\n\\\\u001b[1;32m    870\\\\u001b[0m     \\\\u001b[38;5;66;03m# Binary mode does not support \\'encoding\\' and \\'newline\\'.\\\\u001b[39;00m\\\\n\\\\u001b[1;32m    871\\\\u001b[0m     \\\\u001b[38;5;28;01mif\\\\u001b[39;00m ioargs\\\\u001b[38;5;241m.\\\\u001b[39mencoding \\\\u001b[38;5;129;01mand\\\\u001b[39;00m \\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mb\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m \\\\u001b[38;5;129;01mnot\\\\u001b[39;00m \\\\u001b[38;5;129;01min\\\\u001b[39;00m ioargs\\\\u001b[38;5;241m.\\\\u001b[39mmode:\\\\n\\\\u001b[1;32m    872\\\\u001b[0m         \\\\u001b[38;5;66;03m# Encoding\\\\u001b[39;00m\\\\n\\\\u001b[0;32m--> 873\\\\u001b[0m         handle \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;28mopen\\\\u001b[39m(\\\\n\\\\u001b[1;32m    874\\\\u001b[0m             handle,\\\\n\\\\u001b[1;32m    875\\\\u001b[0m             ioargs\\\\u001b[38;5;241m.\\\\u001b[39mmode,\\\\n\\\\u001b[1;32m    876\\\\u001b[0m             encoding\\\\u001b[38;5;241m=\\\\u001b[39mioargs\\\\u001b[38;5;241m.\\\\u001b[39mencoding,\\\\n\\\\u001b[1;32m    877\\\\u001b[0m             errors\\\\u001b[38;5;241m=\\\\u001b[39merrors,\\\\n\\\\u001b[1;32m    878\\\\u001b[0m             newline\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m,\\\\n\\\\u001b[1;32m    879\\\\u001b[0m         )\\\\n\\\\u001b[1;32m    880\\\\u001b[0m     \\\\u001b[38;5;28;01melse\\\\u001b[39;00m:\\\\n\\\\u001b[1;32m    881\\\\u001b[0m         \\\\u001b[38;5;66;03m# Binary mode\\\\u001b[39;00m\\\\n\\\\u001b[1;32m    882\\\\u001b[0m         handle \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;28mopen\\\\u001b[39m(handle, ioargs\\\\u001b[38;5;241m.\\\\u001b[39mmode)\\\\n\",\\n      \"\\\\u001b[0;31mFileNotFoundError\\\\u001b[0m: [Errno 2] No such file or directory: \\'/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv\\'\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"import pandas as pd\\\\n\",\\n    \"\\\\n\",\\n    \"# Define the file path\\\\n\",\\n    \"file_path = \\'/Volumes/One Touch/World University Ranking/02 Data/Original Data/cwurData.csv\\'\\\\n\",\\n    \"\\\\n\",\\n    \"# Load the data into a pandas DataFrame\\\\n\",\\n    \"df = pd.read_csv(file_path)\\\\n\",\\n    \"\\\\n\",\\n    \"# Display the first few rows to understand the structure of the data\\\\n\",\\n    \"print(\\\\\"Initial data preview:\\\\\")\\\\n\",\\n    \"print(df.head())\\\\n\",\\n    \"\\\\n\",\\n    \"# Example of data cleaning operations:\\\\n\",\\n    \"# 1. Handling missing values (if any)\\\\n\",\\n    \"# Replace missing values with NaN\\\\n\",\\n    \"df.replace(\\'na\\', pd.NA, inplace=True)\\\\n\",\\n    \"df.replace(\\'NA\\', pd.NA, inplace=True)\\\\n\",\\n    \"df.replace(\\'-\\', pd.NA, inplace=True)\\\\n\",\\n    \"\\\\n\",\\n    \"# 2. Dropping duplicates (if necessary)\\\\n\",\\n    \"df.drop_duplicates(inplace=True)\\\\n\",\\n    \"\\\\n\",\\n    \"# 3. Data type conversions (if necessary)\\\\n\",\\n    \"# For example, converting numeric columns from string to numeric\\\\n\",\\n    \"numeric_columns = [\\'score\\', \\'national_rank\\', \\'quality_of_education\\']\\\\n\",\\n    \"df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors=\\'coerce\\')\\\\n\",\\n    \"\\\\n\",\\n    \"# 4. Renaming columns (if necessary)\\\\n\",\\n    \"# Example: Rename columns for better readability\\\\n\",\\n    \"df.rename(columns={\\'institution\\': \\'university_name\\', \\'country\\': \\'country_name\\'}, inplace=True)\\\\n\",\\n    \"\\\\n\",\\n    \"\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 11,\\n   \"id\": \"a80b7632\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"File exists!\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"import os\\\\n\",\\n    \"\\\\n\",\\n    \"file_path = \\'//Users/yonathanciotta/Downloads/cwurData.csv\\'\\\\n\",\\n    \"if os.path.exists(file_path):\\\\n\",\\n    \"    print(\\\\\"File exists!\\\\\")\\\\n\",\\n    \"else:\\\\n\",\\n    \"    print(\\\\\"File not found.\\\\\")\\\\n\",\\n    \"\\\\n\",\\n    \"    \"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 12,\\n   \"id\": \"71da6742\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"Initial data preview:\\\\n\",\\n      \"   world_rank                            institution         country  \\\\\\\\\\\\n\",\\n      \"0           1                     Harvard University             USA   \\\\n\",\\n      \"1           2  Massachusetts Institute of Technology             USA   \\\\n\",\\n      \"2           3                    Stanford University             USA   \\\\n\",\\n      \"3           4                University of Cambridge  United Kingdom   \\\\n\",\\n      \"4           5     California Institute of Technology             USA   \\\\n\",\\n      \"\\\\n\",\\n      \"   national_rank  quality_of_education  alumni_employment  quality_of_faculty  \\\\\\\\\\\\n\",\\n      \"0              1                     7                  9                   1   \\\\n\",\\n      \"1              2                     9                 17                   3   \\\\n\",\\n      \"2              3                    17                 11                   5   \\\\n\",\\n      \"3              1                    10                 24                   4   \\\\n\",\\n      \"4              4                     2                 29                   7   \\\\n\",\\n      \"\\\\n\",\\n      \"   publications  influence  citations  broad_impact  patents   score  year  \\\\n\",\\n      \"0             1          1          1           NaN        5  100.00  2012  \\\\n\",\\n      \"1            12          4          4           NaN        1   91.67  2012  \\\\n\",\\n      \"2             4          2          2           NaN       15   89.50  2012  \\\\n\",\\n      \"3            16         16         11           NaN       50   86.17  2012  \\\\n\",\\n      \"4            37         22         22           NaN       18   85.21  2012  \\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"import pandas as pd\\\\n\",\\n    \"\\\\n\",\\n    \"# Define the file path\\\\n\",\\n    \"file_path = \\'/Users/yonathanciotta/Downloads/cwurData.csv\\'\\\\n\",\\n    \"\\\\n\",\\n    \"# Load the data into a pandas DataFrame\\\\n\",\\n    \"df = pd.read_csv(file_path)\\\\n\",\\n    \"\\\\n\",\\n    \"# Display the first few rows to understand the structure of the data\\\\n\",\\n    \"print(\\\\\"Initial data preview:\\\\\")\\\\n\",\\n    \"print(df.head())\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 13,\\n   \"id\": \"0e325e33\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"Missing Values:\\\\n\",\\n      \" world_rank                0\\\\n\",\\n      \"institution               0\\\\n\",\\n      \"country                   0\\\\n\",\\n      \"national_rank             0\\\\n\",\\n      \"quality_of_education      0\\\\n\",\\n      \"alumni_employment         0\\\\n\",\\n      \"quality_of_faculty        0\\\\n\",\\n      \"publications              0\\\\n\",\\n      \"influence                 0\\\\n\",\\n      \"citations                 0\\\\n\",\\n      \"broad_impact            200\\\\n\",\\n      \"patents                   0\\\\n\",\\n      \"score                     0\\\\n\",\\n      \"year                      0\\\\n\",\\n      \"dtype: int64\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"# Check for missing values\\\\n\",\\n    \"missing_values = df.isnull().sum()\\\\n\",\\n    \"print(\\\\\"Missing Values:\\\\\\\\n\\\\\", missing_values)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 14,\\n   \"id\": \"8a422432\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# Convert \\'year\\' column to datetime format (if not already)\\\\n\",\\n    \"df[\\'year\\'] = pd.to_datetime(df[\\'year\\'], format=\\'%Y\\')\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 15,\\n   \"id\": \"5b6d34cc\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# Remove duplicate rows if any\\\\n\",\\n    \"df.drop_duplicates(inplace=True)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 16,\\n   \"id\": \"1b5d997e\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# Example: Rename columns to lowercase for consistency\\\\n\",\\n    \"df.columns = df.columns.str.lower()\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 18,\\n   \"id\": \"68158eca\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# Example: Standardize country names (assuming \\'country\\' column)\\\\n\",\\n    \"df[\\'country\\'] = df[\\'country\\'].str.strip().str.lower().replace({\\\\n\",\\n    \"    \\'united states of america\\': \\'usa\\',\\\\n\",\\n    \"    \\'united kingdom\\': \\'uk\\',\\\\n\",\\n    \"    \\\\n\",\\n    \"})\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 19,\\n   \"id\": \"0b85ed77\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"Cleaned data saved to /Users/yonathanciotta/Downloads/cwurData_cleaned.csv\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"# Save cleaned DataFrame to a new CSV file\\\\n\",\\n    \"cleaned_file_path = \\'/Users/yonathanciotta/Downloads/cwurData_cleaned.csv\\'\\\\n\",\\n    \"df.to_csv(cleaned_file_path, index=False)\\\\n\",\\n    \"print(f\\\\\"Cleaned data saved to {cleaned_file_path}\\\\\")\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 20,\\n   \"id\": \"68a1da5d\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# Drop rows where broad_impact is NaN\\\\n\",\\n    \"df.dropna(subset=[\\'broad_impact\\'], inplace=True)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 21,\\n   \"id\": \"9c049b84\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stderr\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"/var/folders/r3/g4d_jbx96_zbkgnnptpzq5sr0000gn/T/ipykernel_3064/75163870.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\\\\n\",\\n      \"The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\\\\n\",\\n      \"\\\\n\",\\n      \"For example, when doing \\'df[col].method(value, inplace=True)\\', try using \\'df.method({col: value}, inplace=True)\\' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\\\\n\",\\n      \"\\\\n\",\\n      \"\\\\n\",\\n      \"  df[\\'broad_impact\\'].fillna(mean_broad_impact, inplace=True)\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"# Example: Impute missing values with the mean of the column\\\\n\",\\n    \"mean_broad_impact = df[\\'broad_impact\\'].mean()\\\\n\",\\n    \"df[\\'broad_impact\\'].fillna(mean_broad_impact, inplace=True)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 22,\\n   \"id\": \"cb8fbaca\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"Missing Values after cleaning:\\\\n\",\\n      \" world_rank              0\\\\n\",\\n      \"institution             0\\\\n\",\\n      \"country                 0\\\\n\",\\n      \"national_rank           0\\\\n\",\\n      \"quality_of_education    0\\\\n\",\\n      \"alumni_employment       0\\\\n\",\\n      \"quality_of_faculty      0\\\\n\",\\n      \"publications            0\\\\n\",\\n      \"influence               0\\\\n\",\\n      \"citations               0\\\\n\",\\n      \"broad_impact            0\\\\n\",\\n      \"patents                 0\\\\n\",\\n      \"score                   0\\\\n\",\\n      \"year                    0\\\\n\",\\n      \"dtype: int64\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"# Drop rows where broad_impact is NaN\\\\n\",\\n    \"df_cleaned = df.dropna(subset=[\\'broad_impact\\'])\\\\n\",\\n    \"\\\\n\",\\n    \"# Confirming the missing values after cleaning\\\\n\",\\n    \"missing_values_cleaned = df_cleaned.isnull().sum()\\\\n\",\\n    \"print(\\\\\"Missing Values after cleaning:\\\\\\\\n\\\\\", missing_values_cleaned)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 23,\\n   \"id\": \"0efe954b\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# Calculate mean of broad_impact\\\\n\",\\n    \"mean_broad_impact = df[\\'broad_impact\\'].mean()\\\\n\",\\n    \"\\\\n\",\\n    \"# Fill missing values with mean using a dictionary\\\\n\",\\n    \"df[\\'broad_impact\\'] = df[\\'broad_impact\\'].fillna(mean_broad_impact)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 24,\\n   \"id\": \"02d38bf1\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# Calculate mean of broad_impact\\\\n\",\\n    \"mean_broad_impact = df[\\'broad_impact\\'].mean()\\\\n\",\\n    \"\\\\n\",\\n    \"# Directly assign the filled values\\\\n\",\\n    \"df[\\'broad_impact\\'] = df[\\'broad_impact\\'].fillna(mean_broad_impact)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 25,\\n   \"id\": \"5a715cef\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"Missing Values after cleaning:\\\\n\",\\n      \" world_rank              0\\\\n\",\\n      \"institution             0\\\\n\",\\n      \"country                 0\\\\n\",\\n      \"national_rank           0\\\\n\",\\n      \"quality_of_education    0\\\\n\",\\n      \"alumni_employment       0\\\\n\",\\n      \"quality_of_faculty      0\\\\n\",\\n      \"publications            0\\\\n\",\\n      \"influence               0\\\\n\",\\n      \"citations               0\\\\n\",\\n      \"broad_impact            0\\\\n\",\\n      \"patents                 0\\\\n\",\\n      \"score                   0\\\\n\",\\n      \"year                    0\\\\n\",\\n      \"dtype: int64\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"\\\\n\",\\n    \"\\\\n\",\\n    \"\\\\n\",\\n    \"# Calculate mean of broad_impact\\\\n\",\\n    \"mean_broad_impact = df[\\'broad_impact\\'].mean()\\\\n\",\\n    \"\\\\n\",\\n    \"# Fill missing values in broad_impact column\\\\n\",\\n    \"df[\\'broad_impact\\'] = df[\\'broad_impact\\'].fillna(mean_broad_impact)\\\\n\",\\n    \"\\\\n\",\\n    \"# Confirming the missing values after cleaning\\\\n\",\\n    \"missing_values_cleaned = df.isnull().sum()\\\\n\",\\n    \"print(\\\\\"Missing Values after cleaning:\\\\\\\\n\\\\\", missing_values_cleaned)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 26,\\n   \"id\": \"fa9cb302\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"\\\\n\",\\n      \"Descriptive Statistics:\\\\n\",\\n      \"        world_rank  national_rank  quality_of_education  alumni_employment  \\\\\\\\\\\\n\",\\n      \"count  2000.000000    2000.000000           2000.000000        2000.000000   \\\\n\",\\n      \"mean    500.500000      42.518000            296.001500         385.263500   \\\\n\",\\n      \"min       1.000000       1.000000              1.000000           1.000000   \\\\n\",\\n      \"25%     250.750000       7.000000            250.750000         250.750000   \\\\n\",\\n      \"50%     500.500000      22.000000            355.000000         478.000000   \\\\n\",\\n      \"75%     750.250000      52.000000            367.000000         500.250000   \\\\n\",\\n      \"max    1000.000000     229.000000            367.000000         567.000000   \\\\n\",\\n      \"std     288.747186      53.444193            106.868798         171.874782   \\\\n\",\\n      \"\\\\n\",\\n      \"       quality_of_faculty  publications   influence    citations  \\\\\\\\\\\\n\",\\n      \"count         2000.000000   2000.000000  2000.00000  2000.000000   \\\\n\",\\n      \"mean           191.127500    500.415000   500.21900   449.341500   \\\\n\",\\n      \"min              1.000000      1.000000     1.00000     1.000000   \\\\n\",\\n      \"25%            210.000000    250.750000   250.75000   234.000000   \\\\n\",\\n      \"50%            210.000000    500.500000   500.50000   428.000000   \\\\n\",\\n      \"75%            218.000000    750.000000   750.25000   645.000000   \\\\n\",\\n      \"max            218.000000   1000.000000   991.00000   812.000000   \\\\n\",\\n      \"std             52.402579    288.674823   288.30505   250.141228   \\\\n\",\\n      \"\\\\n\",\\n      \"       broad_impact      patents        score                 year  \\\\n\",\\n      \"count   2000.000000  2000.000000  2000.000000                 2000  \\\\n\",\\n      \"mean     496.699500   470.321000    47.067630  2014-07-02 12:00:00  \\\\n\",\\n      \"min        1.000000     1.000000    44.020000  2014-01-01 00:00:00  \\\\n\",\\n      \"25%      250.500000   242.750000    44.440000  2014-01-01 00:00:00  \\\\n\",\\n      \"50%      496.000000   481.000000    44.960000  2014-07-02 12:00:00  \\\\n\",\\n      \"75%      741.000000   737.000000    46.812500  2015-01-01 00:00:00  \\\\n\",\\n      \"max     1000.000000   871.000000   100.000000  2015-01-01 00:00:00  \\\\n\",\\n      \"std      286.919755   259.625408     6.590461                  NaN  \\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"# Basic descriptive statistics\\\\n\",\\n    \"descriptive_stats = df.describe()\\\\n\",\\n    \"\\\\n\",\\n    \"# Displaying descriptive statistics\\\\n\",\\n    \"print(\\\\\"\\\\\\\\nDescriptive Statistics:\\\\\")\\\\n\",\\n    \"print(descriptive_stats)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 27,\\n   \"id\": \"1e26f6b7\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"\\\\n\",\\n      \"Data types and non-null counts:\\\\n\",\\n      \"<class \\'pandas.core.frame.DataFrame\\'>\\\\n\",\\n      \"Index: 2000 entries, 200 to 2199\\\\n\",\\n      \"Data columns (total 14 columns):\\\\n\",\\n      \" #   Column                Non-Null Count  Dtype         \\\\n\",\\n      \"---  ------                --------------  -----         \\\\n\",\\n      \" 0   world_rank            2000 non-null   int64         \\\\n\",\\n      \" 1   institution           2000 non-null   object        \\\\n\",\\n      \" 2   country               2000 non-null   object        \\\\n\",\\n      \" 3   national_rank         2000 non-null   int64         \\\\n\",\\n      \" 4   quality_of_education  2000 non-null   int64         \\\\n\",\\n      \" 5   alumni_employment     2000 non-null   int64         \\\\n\",\\n      \" 6   quality_of_faculty    2000 non-null   int64         \\\\n\",\\n      \" 7   publications          2000 non-null   int64         \\\\n\",\\n      \" 8   influence             2000 non-null   int64         \\\\n\",\\n      \" 9   citations             2000 non-null   int64         \\\\n\",\\n      \" 10  broad_impact          2000 non-null   float64       \\\\n\",\\n      \" 11  patents               2000 non-null   int64         \\\\n\",\\n      \" 12  score                 2000 non-null   float64       \\\\n\",\\n      \" 13  year                  2000 non-null   datetime64[ns]\\\\n\",\\n      \"dtypes: datetime64[ns](1), float64(2), int64(9), object(2)\\\\n\",\\n      \"memory usage: 234.4+ KB\\\\n\",\\n      \"None\\\\n\",\\n      \"\\\\n\",\\n      \"Missing Values:\\\\n\",\\n      \"world_rank              0\\\\n\",\\n      \"institution             0\\\\n\",\\n      \"country                 0\\\\n\",\\n      \"national_rank           0\\\\n\",\\n      \"quality_of_education    0\\\\n\",\\n      \"alumni_employment       0\\\\n\",\\n      \"quality_of_faculty      0\\\\n\",\\n      \"publications            0\\\\n\",\\n      \"influence               0\\\\n\",\\n      \"citations               0\\\\n\",\\n      \"broad_impact            0\\\\n\",\\n      \"patents                 0\\\\n\",\\n      \"score                   0\\\\n\",\\n      \"year                    0\\\\n\",\\n      \"dtype: int64\\\\n\",\\n      \"\\\\n\",\\n      \"Unique values in \\'country\\' column:\\\\n\",\\n      \"[\\'usa\\' \\'uk\\' \\'japan\\' \\'switzerland\\' \\'israel\\' \\'south korea\\' \\'canada\\' \\'france\\'\\\\n\",\\n      \" \\'russia\\' \\'china\\' \\'taiwan\\' \\'sweden\\' \\'singapore\\' \\'denmark\\' \\'germany\\'\\\\n\",\\n      \" \\'netherlands\\' \\'italy\\' \\'belgium\\' \\'australia\\' \\'finland\\' \\'norway\\'\\\\n\",\\n      \" \\'south africa\\' \\'spain\\' \\'brazil\\' \\'hong kong\\' \\'ireland\\' \\'austria\\'\\\\n\",\\n      \" \\'new zealand\\' \\'portugal\\' \\'thailand\\' \\'czech republic\\' \\'malaysia\\' \\'india\\'\\\\n\",\\n      \" \\'greece\\' \\'mexico\\' \\'hungary\\' \\'argentina\\' \\'turkey\\' \\'poland\\' \\'saudi arabia\\'\\\\n\",\\n      \" \\'chile\\' \\'iceland\\' \\'slovenia\\' \\'estonia\\' \\'lebanon\\' \\'croatia\\' \\'colombia\\'\\\\n\",\\n      \" \\'slovak republic\\' \\'iran\\' \\'egypt\\' \\'serbia\\' \\'bulgaria\\' \\'lithuania\\' \\'uganda\\'\\\\n\",\\n      \" \\'united arab emirates\\' \\'uruguay\\' \\'cyprus\\' \\'romania\\' \\'puerto rico\\']\\\\n\",\\n      \"\\\\n\",\\n      \"Value counts in \\'country\\' column:\\\\n\",\\n      \"country\\\\n\",\\n      \"usa                     458\\\\n\",\\n      \"china                   167\\\\n\",\\n      \"japan                   148\\\\n\",\\n      \"uk                      129\\\\n\",\\n      \"germany                 110\\\\n\",\\n      \"france                   99\\\\n\",\\n      \"italy                    94\\\\n\",\\n      \"spain                    81\\\\n\",\\n      \"south korea              70\\\\n\",\\n      \"canada                   65\\\\n\",\\n      \"australia                54\\\\n\",\\n      \"taiwan                   46\\\\n\",\\n      \"brazil                   36\\\\n\",\\n      \"india                    31\\\\n\",\\n      \"netherlands              26\\\\n\",\\n      \"austria                  24\\\\n\",\\n      \"sweden                   22\\\\n\",\\n      \"turkey                   20\\\\n\",\\n      \"belgium                  20\\\\n\",\\n      \"finland                  18\\\\n\",\\n      \"poland                   18\\\\n\",\\n      \"switzerland              18\\\\n\",\\n      \"iran                     16\\\\n\",\\n      \"ireland                  16\\\\n\",\\n      \"greece                   14\\\\n\",\\n      \"portugal                 14\\\\n\",\\n      \"israel                   14\\\\n\",\\n      \"hungary                  12\\\\n\",\\n      \"hong kong                12\\\\n\",\\n      \"new zealand              12\\\\n\",\\n      \"norway                   10\\\\n\",\\n      \"czech republic           10\\\\n\",\\n      \"south africa             10\\\\n\",\\n      \"denmark                  10\\\\n\",\\n      \"egypt                     8\\\\n\",\\n      \"chile                     8\\\\n\",\\n      \"saudi arabia              8\\\\n\",\\n      \"russia                    8\\\\n\",\\n      \"argentina                 7\\\\n\",\\n      \"thailand                  6\\\\n\",\\n      \"malaysia                  6\\\\n\",\\n      \"mexico                    4\\\\n\",\\n      \"colombia                  4\\\\n\",\\n      \"singapore                 4\\\\n\",\\n      \"slovenia                  4\\\\n\",\\n      \"romania                   3\\\\n\",\\n      \"lebanon                   2\\\\n\",\\n      \"croatia                   2\\\\n\",\\n      \"estonia                   2\\\\n\",\\n      \"slovak republic           2\\\\n\",\\n      \"iceland                   2\\\\n\",\\n      \"serbia                    2\\\\n\",\\n      \"bulgaria                  2\\\\n\",\\n      \"lithuania                 2\\\\n\",\\n      \"uganda                    2\\\\n\",\\n      \"united arab emirates      2\\\\n\",\\n      \"uruguay                   2\\\\n\",\\n      \"cyprus                    2\\\\n\",\\n      \"puerto rico               2\\\\n\",\\n      \"Name: count, dtype: int64\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"# Checking data types and non-null counts\\\\n\",\\n    \"print(\\\\\"\\\\\\\\nData types and non-null counts:\\\\\")\\\\n\",\\n    \"print(df.info())\\\\n\",\\n    \"\\\\n\",\\n    \"# Checking for missing values again after cleaning\\\\n\",\\n    \"missing_values = df.isnull().sum()\\\\n\",\\n    \"print(\\\\\"\\\\\\\\nMissing Values:\\\\\")\\\\n\",\\n    \"print(missing_values)\\\\n\",\\n    \"\\\\n\",\\n    \"# Checking unique values in categorical columns\\\\n\",\\n    \"print(\\\\\"\\\\\\\\nUnique values in \\'country\\' column:\\\\\")\\\\n\",\\n    \"print(df[\\'country\\'].unique())\\\\n\",\\n    \"\\\\n\",\\n    \"# Checking value counts in categorical columns\\\\n\",\\n    \"print(\\\\\"\\\\\\\\nValue counts in \\'country\\' column:\\\\\")\\\\n\",\\n    \"print(df[\\'country\\'].value_counts())\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 28,\\n   \"id\": \"553612ea\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"ename\": \"FileNotFoundError\",\\n     \"evalue\": \"[Errno 2] No such file or directory: \\'/Users/yonathanciotta/Downloads/World_University_Ranking.ipynb\\'\",\\n     \"output_type\": \"error\",\\n     \"traceback\": [\\n      \"\\\\u001b[0;31m---------------------------------------------------------------------------\\\\u001b[0m\",\\n      \"\\\\u001b[0;31mFileNotFoundError\\\\u001b[0m                         Traceback (most recent call last)\",\\n      \"Cell \\\\u001b[0;32mIn[28], line 17\\\\u001b[0m\\\\n\\\\u001b[1;32m     14\\\\u001b[0m destination_pickle_path \\\\u001b[38;5;241m=\\\\u001b[39m os\\\\u001b[38;5;241m.\\\\u001b[39mpath\\\\u001b[38;5;241m.\\\\u001b[39mjoin(destination_directory, pickle_filename)\\\\n\\\\u001b[1;32m     16\\\\u001b[0m \\\\u001b[38;5;66;03m# Serialize and save the notebook as a pickle file\\\\u001b[39;00m\\\\n\\\\u001b[0;32m---> 17\\\\u001b[0m \\\\u001b[38;5;28;01mwith\\\\u001b[39;00m \\\\u001b[38;5;28mopen\\\\u001b[39m(current_notebook_path, \\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\u001b[38;5;124mrb\\\\u001b[39m\\\\u001b[38;5;124m\\'\\\\u001b[39m) \\\\u001b[38;5;28;01mas\\\\u001b[39;00m notebook_file:\\\\n\\\\u001b[1;32m     18\\\\u001b[0m     notebook_content \\\\u001b[38;5;241m=\\\\u001b[39m notebook_file\\\\u001b[38;5;241m.\\\\u001b[39mread()\\\\n\\\\u001b[1;32m     19\\\\u001b[0m     \\\\u001b[38;5;28;01mwith\\\\u001b[39;00m \\\\u001b[38;5;28mopen\\\\u001b[39m(destination_pickle_path, \\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\u001b[38;5;124mwb\\\\u001b[39m\\\\u001b[38;5;124m\\'\\\\u001b[39m) \\\\u001b[38;5;28;01mas\\\\u001b[39;00m pickle_file:\\\\n\",\\n      \"File \\\\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\\\\u001b[0m, in \\\\u001b[0;36m_modified_open\\\\u001b[0;34m(file, *args, **kwargs)\\\\u001b[0m\\\\n\\\\u001b[1;32m    303\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m file \\\\u001b[38;5;129;01min\\\\u001b[39;00m {\\\\u001b[38;5;241m0\\\\u001b[39m, \\\\u001b[38;5;241m1\\\\u001b[39m, \\\\u001b[38;5;241m2\\\\u001b[39m}:\\\\n\\\\u001b[1;32m    304\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m \\\\u001b[38;5;167;01mValueError\\\\u001b[39;00m(\\\\n\\\\u001b[1;32m    305\\\\u001b[0m         \\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mIPython won\\\\u001b[39m\\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\u001b[38;5;124mt let you open fd=\\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00mfile\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m by default \\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\n\\\\u001b[1;32m    306\\\\u001b[0m         \\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\n\\\\u001b[1;32m    307\\\\u001b[0m         \\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\u001b[38;5;124myou can use builtins\\\\u001b[39m\\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\u001b[38;5;124m open.\\\\u001b[39m\\\\u001b[38;5;124m\\\\\"\\\\u001b[39m\\\\n\\\\u001b[1;32m    308\\\\u001b[0m     )\\\\n\\\\u001b[0;32m--> 310\\\\u001b[0m \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m io_open(file, \\\\u001b[38;5;241m*\\\\u001b[39margs, \\\\u001b[38;5;241m*\\\\u001b[39m\\\\u001b[38;5;241m*\\\\u001b[39mkwargs)\\\\n\",\\n      \"\\\\u001b[0;31mFileNotFoundError\\\\u001b[0m: [Errno 2] No such file or directory: \\'/Users/yonathanciotta/Downloads/World_University_Ranking.ipynb\\'\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"import pickle\\\\n\",\\n    \"import shutil\\\\n\",\\n    \"import os\\\\n\",\\n    \"\\\\n\",\\n    \"# Get the current notebook file path\\\\n\",\\n    \"notebook_filename = \\'World_University_Ranking.ipynb\\'  \\\\n\",\\n    \"current_notebook_path = os.path.abspath(notebook_filename)\\\\n\",\\n    \"\\\\n\",\\n    \"# Specify the destination directory\\\\n\",\\n    \"destination_directory = \\'/Users/yonathanciotta/Downloads/\\'\\\\n\",\\n    \"\\\\n\",\\n    \"# Construct the destination pickle file path\\\\n\",\\n    \"pickle_filename = \\'World_University_Ranking.pkl\\'  \\\\n\",\\n    \"destination_pickle_path = os.path.join(destination_directory, pickle_filename)\\\\n\",\\n    \"\\\\n\",\\n    \"# Serialize and save the notebook as a pickle file\\\\n\",\\n    \"with open(current_notebook_path, \\'rb\\') as notebook_file:\\\\n\",\\n    \"    notebook_content = notebook_file.read()\\\\n\",\\n    \"    with open(destination_pickle_path, \\'wb\\') as pickle_file:\\\\n\",\\n    \"        pickle.dump(notebook_content, pickle_file)\\\\n\",\\n    \"\\\\n\",\\n    \"print(f\\\\\"Notebook saved as pickle to: {destination_pickle_path}\\\\\")\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"id\": \"e7c6df9c\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": []\\n  }\\n ],\\n \"metadata\": {\\n  \"kernelspec\": {\\n   \"display_name\": \"Python 3 (ipykernel)\",\\n   \"language\": \"python\",\\n   \"name\": \"python3\"\\n  },\\n  \"language_info\": {\\n   \"codemirror_mode\": {\\n    \"name\": \"ipython\",\\n    \"version\": 3\\n   },\\n   \"file_extension\": \".py\",\\n   \"mimetype\": \"text/x-python\",\\n   \"name\": \"python\",\\n   \"nbconvert_exporter\": \"python\",\\n   \"pygments_lexer\": \"ipython3\",\\n   \"version\": \"3.11.7\"\\n  }\\n },\\n \"nbformat\": 4,\\n \"nbformat_minor\": 5\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the path to the pickle file\n",
    "pickle_filepath = '/Users/yonathanciotta/Downloads/World_University_Ranking.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pickle_filepath, 'rb') as file:\n",
    "    notebook_content = pickle.load(file)\n",
    "\n",
    "# Verify the loaded content (if needed)\n",
    "print(notebook_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb977ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as pickle to: /Users/yonathanciotta/Downloads/cleaned_cwurData.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your cleaned DataFrame is named df\n",
    "# Define the path to save the pickle file\n",
    "pickle_path = '/Users/yonathanciotta/Downloads/cleaned_cwurData.pkl'\n",
    "\n",
    "# Save the DataFrame as a pickle file\n",
    "df.to_pickle(pickle_path)\n",
    "\n",
    "print(f\"DataFrame saved as pickle to: {pickle_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68d89d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     world_rank                            institution country  national_rank  \\\n",
      "200           1                     Harvard University     usa              1   \n",
      "201           2                    Stanford University     usa              2   \n",
      "202           3  Massachusetts Institute of Technology     usa              3   \n",
      "203           4                University of Cambridge      uk              1   \n",
      "204           5                   University of Oxford      uk              2   \n",
      "\n",
      "     quality_of_education  alumni_employment  quality_of_faculty  \\\n",
      "200                     1                  1                   1   \n",
      "201                    11                  2                   4   \n",
      "202                     3                 11                   2   \n",
      "203                     2                 10                   5   \n",
      "204                     7                 12                  10   \n",
      "\n",
      "     publications  influence  citations  broad_impact  patents   score  \\\n",
      "200             1          1          1           1.0        2  100.00   \n",
      "201             5          3          3           4.0        6   99.09   \n",
      "202            15          2          2           2.0        1   98.69   \n",
      "203            10          9         12          13.0       48   97.64   \n",
      "204            11         12         11          12.0       16   97.51   \n",
      "\n",
      "          year  \n",
      "200 2014-01-01  \n",
      "201 2014-01-01  \n",
      "202 2014-01-01  \n",
      "203 2014-01-01  \n",
      "204 2014-01-01  \n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame from the pickle file\n",
    "loaded_df = pd.read_pickle(pickle_path)\n",
    "\n",
    "# Verify the loaded DataFrame\n",
    "print(loaded_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4335b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
